#!/usr/bin/env python3
"""
QualityGate Phase 3A Week 2 - Enhanced Pattern Detector
é«˜ç²¾åº¦ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•æ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³

Week 2 å¼·åŒ–å†…å®¹:
1. ã‚ˆã‚Šè©³ç´°ãªASTãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
2. çµ±è¨ˆçš„ä¿¡é ¼åº¦è¨ˆç®—
3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
4. False Positiveå‰Šæ¸›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
"""

import ast
import re
import json
import time
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
from enum import Enum
import statistics

class PatternType(Enum):
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—åˆ†é¡"""
    NAMING_CONVENTION = "naming_convention"
    IMPORT_STYLE = "import_style"
    CODE_STRUCTURE = "code_structure"
    ERROR_HANDLING = "error_handling"
    DOCUMENTATION = "documentation"
    COMPLEXITY = "complexity"
    SECURITY = "security"
    PROJECT_SPECIFIC = "project_specific"

@dataclass
class EnhancedCodePattern:
    """å¼·åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³"""
    pattern_id: str
    pattern_type: PatternType
    pattern_regex: str
    confidence_score: float  # 0.0-1.0
    frequency: int
    evidence_files: List[str]
    counter_examples: List[str]
    suggested_message: str
    severity: str  # CRITICAL, HIGH, INFO
    auto_fixable: bool = False
    related_patterns: List[str] = None
    
    def __post_init__(self):
        if self.related_patterns is None:
            self.related_patterns = []

@dataclass
class ProjectProfile:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«"""
    project_type: str  # web, cli, library, data_science, etc.
    primary_frameworks: List[str]
    coding_style: Dict[str, str]
    complexity_level: str  # simple, medium, complex
    team_size_indicator: str  # solo, small, medium, large
    maturity_level: str  # prototype, development, production

class EnhancedPatternDetector:
    """å¼·åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.detected_patterns: List[EnhancedCodePattern] = []
        self.project_profile: Optional[ProjectProfile] = None
        
        # æ¤œå‡ºç²¾åº¦å‘ä¸Šã®ãŸã‚ã®é–¾å€¤
        self.min_pattern_frequency = 3
        self.min_confidence_score = 0.7
        self.max_false_positive_rate = 0.15
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®šãƒ«ãƒ¼ãƒ«
        self.project_type_indicators = {
            'web': ['django', 'flask', 'fastapi', 'starlette', 'tornado'],
            'cli': ['click', 'argparse', 'typer', 'fire'],
            'data_science': ['pandas', 'numpy', 'sklearn', 'matplotlib', 'jupyter'],
            'library': ['setuptools', '__init__.py', 'setup.py'],
            'testing': ['pytest', 'unittest', 'nose', 'tox']
        }
        
        # å‘½åè¦å‰‡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰
        self.naming_patterns = {
            'snake_case_functions': {
                'regex': r'^[a-z_][a-z0-9_]*$',
                'counter_regex': r'^[A-Z][a-zA-Z0-9]*$|^[a-z][a-zA-Z0-9]*$',
                'message': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯snake_caseé–¢æ•°åãŒæ¨™æº–ã§ã™'
            },
            'camel_case_classes': {
                'regex': r'^[A-Z][a-zA-Z0-9]*$',
                'counter_regex': r'^[a-z_][a-z0-9_]*$',
                'message': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯CamelCaseã‚¯ãƒ©ã‚¹åãŒæ¨™æº–ã§ã™'
            },
            'upper_case_constants': {
                'regex': r'^[A-Z][A-Z0-9_]*$',
                'counter_regex': r'^[a-z_][a-z0-9_]*$',
                'message': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯å®šæ•°ã¯UPPER_CASEã§å‘½åã—ã¾ã™'
            },
            'private_methods': {
                'regex': r'^_[a-z_][a-z0-9_]*$',
                'counter_regex': r'^[a-z_][a-z0-9_]*$',
                'message': 'ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã«ã¯å…ˆé ­ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã¦ãã ã•ã„'
            }
        }
        
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.import_style_patterns = {
            'relative_imports': {
                'regex': r'from\s+\.+[a-zA-Z0-9_.]*\s+import',
                'message': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™'
            },
            'absolute_imports': {
                'regex': r'from\s+[a-zA-Z][a-zA-Z0-9_.]*\s+import',
                'message': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™'
            },
            'grouped_imports': {
                'regex': r'import\s+[a-zA-Z0-9_.]+\nimport\s+[a-zA-Z0-9_.]+',
                'message': 'ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã¯ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚Œã¦ã„ã¾ã™'
            }
        }
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.error_handling_patterns = {
            'specific_exceptions': {
                'regex': r'except\s+[A-Z][a-zA-Z]*Error',
                'message': 'å…·ä½“çš„ãªä¾‹å¤–ã‚¿ã‚¤ãƒ—ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™'
            },
            'bare_except': {
                'regex': r'except\s*:',
                'message': 'bare exceptæ–‡ã®ä½¿ç”¨ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ',
                'severity': 'HIGH'
            },
            'finally_blocks': {
                'regex': r'finally\s*:',
                'message': 'finallyãƒ–ãƒ­ãƒƒã‚¯ãŒé©åˆ‡ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™'
            }
        }
    
    def analyze_project_structure(self, file_results: List[Dict]) -> ProjectProfile:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ åˆ†æã—ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆåˆ†æã§ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
        all_imports = []
        for result in file_results:
            if 'imports' in result:
                all_imports.extend(result['imports'])
        
        import_counter = Counter(all_imports)
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—åˆ¤å®š
        project_type = 'general'
        detected_frameworks = []
        
        for ptype, indicators in self.project_type_indicators.items():
            for indicator in indicators:
                if any(indicator in imp for imp in all_imports):
                    project_type = ptype
                    detected_frameworks.append(indicator)
                    break
        
        # ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ
        function_names = []
        class_names = []
        
        for result in file_results:
            if 'functions' in result:
                function_names.extend(result['functions'])
            if 'classes' in result:
                class_names.extend(result['classes'])
        
        # å‘½åè¦å‰‡åˆ†æ
        coding_style = {}
        
        if function_names:
            snake_case_ratio = sum(1 for name in function_names 
                                 if re.match(r'^[a-z_][a-z0-9_]*$', name)) / len(function_names)
            coding_style['function_naming'] = 'snake_case' if snake_case_ratio > 0.7 else 'mixed'
        
        if class_names:
            camel_case_ratio = sum(1 for name in class_names 
                                 if re.match(r'^[A-Z][a-zA-Z0-9]*$', name)) / len(class_names)
            coding_style['class_naming'] = 'camel_case' if camel_case_ratio > 0.7 else 'mixed'
        
        # è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«
        avg_complexity = statistics.mean([r.get('complexity_score', 0) for r in file_results]) if file_results else 0
        
        if avg_complexity < 5:
            complexity_level = 'simple'
        elif avg_complexity < 15:
            complexity_level = 'medium'
        else:
            complexity_level = 'complex'
        
        # ãƒãƒ¼ãƒ ã‚µã‚¤ã‚ºæ¨å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ã¨ã‚³ãƒ¡ãƒ³ãƒˆå¯†åº¦ã‹ã‚‰ï¼‰
        total_files = len(file_results)
        if total_files < 10:
            team_size_indicator = 'solo'
        elif total_files < 50:
            team_size_indicator = 'small'
        else:
            team_size_indicator = 'medium'
        
        return ProjectProfile(
            project_type=project_type,
            primary_frameworks=detected_frameworks,
            coding_style=coding_style,
            complexity_level=complexity_level,
            team_size_indicator=team_size_indicator,
            maturity_level='development'  # åˆæœŸå€¤
        )
    
    def detect_naming_patterns(self, file_results: List[Dict]) -> List[EnhancedCodePattern]:
        """å‘½åè¦å‰‡ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        patterns = []
        
        # é–¢æ•°ååé›†
        all_function_names = []
        function_files = {}
        
        for result in file_results:
            if 'functions' in result:
                for func_name in result['functions']:
                    all_function_names.append(func_name)
                    function_files[func_name] = result.get('file_path', 'unknown')
        
        # ã‚¯ãƒ©ã‚¹ååé›†
        all_class_names = []
        class_files = {}
        
        for result in file_results:
            if 'classes' in result:
                for class_name in result['classes']:
                    all_class_names.append(class_name)
                    class_files[class_name] = result.get('file_path', 'unknown')
        
        # é–¢æ•°å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if len(all_function_names) >= self.min_pattern_frequency:
            snake_case_functions = [name for name in all_function_names 
                                  if re.match(r'^[a-z_][a-z0-9_]*$', name)]
            
            confidence = len(snake_case_functions) / len(all_function_names)
            
            if confidence >= self.min_confidence_score:
                patterns.append(EnhancedCodePattern(
                    pattern_id='snake_case_functions',
                    pattern_type=PatternType.NAMING_CONVENTION,
                    pattern_regex=r'def\s+[A-Z][a-zA-Z0-9]*\s*\(',
                    confidence_score=confidence,
                    frequency=len(snake_case_functions),
                    evidence_files=list(set(function_files[name] for name in snake_case_functions[:5])),
                    counter_examples=[name for name in all_function_names 
                                    if not re.match(r'^[a-z_][a-z0-9_]*$', name)][:3],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯snake_caseé–¢æ•°åãŒæ¨™æº–ã§ã™ï¼ˆé©ç”¨ç‡: {confidence:.1%}ï¼‰',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        # ã‚¯ãƒ©ã‚¹å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        if len(all_class_names) >= self.min_pattern_frequency:
            camel_case_classes = [name for name in all_class_names 
                                if re.match(r'^[A-Z][a-zA-Z0-9]*$', name)]
            
            confidence = len(camel_case_classes) / len(all_class_names)
            
            if confidence >= self.min_confidence_score:
                patterns.append(EnhancedCodePattern(
                    pattern_id='camel_case_classes',
                    pattern_type=PatternType.NAMING_CONVENTION,
                    pattern_regex=r'class\s+[a-z][a-zA-Z0-9]*\s*[:\(]',
                    confidence_score=confidence,
                    frequency=len(camel_case_classes),
                    evidence_files=list(set(class_files[name] for name in camel_case_classes[:5])),
                    counter_examples=[name for name in all_class_names 
                                    if not re.match(r'^[A-Z][a-zA-Z0-9]*$', name)][:3],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯CamelCaseã‚¯ãƒ©ã‚¹åãŒæ¨™æº–ã§ã™ï¼ˆé©ç”¨ç‡: {confidence:.1%}ï¼‰',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        return patterns
    
    def detect_import_patterns(self, file_results: List[Dict]) -> List[EnhancedCodePattern]:
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        patterns = []
        
        all_imports = []
        import_files = {}
        
        for result in file_results:
            if 'imports' in result:
                for imp in result['imports']:
                    all_imports.append(imp)
                    import_files[imp] = result.get('file_path', 'unknown')
        
        if not all_imports:
            return patterns
        
        # ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
        import_counter = Counter(all_imports)
        
        # é »å‡ºã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦æ¤œå‡º
        for import_name, frequency in import_counter.most_common(10):
            if frequency >= self.min_pattern_frequency:
                confidence = min(0.95, frequency / len(file_results))
                
                if confidence >= self.min_confidence_score:
                    patterns.append(EnhancedCodePattern(
                        pattern_id=f'common_import_{import_name.replace(".", "_")}',
                        pattern_type=PatternType.IMPORT_STYLE,
                        pattern_regex=f'import\\s+(?!{re.escape(import_name)})',
                        confidence_score=confidence,
                        frequency=frequency,
                        evidence_files=[import_files[import_name]],
                        counter_examples=[],
                        suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯{import_name}ãŒæ¨™æº–çš„ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™',
                        severity='INFO',
                        auto_fixable=False
                    ))
        
        # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ vs çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        relative_imports = [imp for imp in all_imports if imp.startswith('.')]
        if len(relative_imports) >= self.min_pattern_frequency:
            confidence = len(relative_imports) / len(all_imports)
            
            if confidence >= 0.3:  # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯30%ã§ã‚‚é‡è¦
                patterns.append(EnhancedCodePattern(
                    pattern_id='relative_imports',
                    pattern_type=PatternType.IMPORT_STYLE,
                    pattern_regex=r'from\s+[a-zA-Z][a-zA-Z0-9_.]*\s+import',
                    confidence_score=confidence,
                    frequency=len(relative_imports),
                    evidence_files=list(set(import_files.get(imp, 'unknown') for imp in relative_imports[:3])),
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ï¼ˆä½¿ç”¨ç‡: {confidence:.1%}ï¼‰',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        return patterns
    
    def detect_code_structure_patterns(self, file_results: List[Dict]) -> List[EnhancedCodePattern]:
        """ã‚³ãƒ¼ãƒ‰æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        patterns = []
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³
        files_with_try_except = 0
        files_with_specific_exceptions = 0
        files_with_bare_except = 0
        files_with_docstrings = 0
        files_with_type_hints = 0
        files_with_logging = 0
        files_with_classes = 0
        files_with_inheritance = 0
        
        structure_files = {
            'try_except': [],
            'specific_exceptions': [],
            'bare_except': [],
            'docstrings': [],
            'type_hints': [],
            'logging': [],
            'inheritance': []
        }
        
        for result in file_results:
            file_path = result.get('file_path', '')
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒå¿…è¦ãªå ´åˆã¯å®Ÿéš›ã«èª­ã¿è¾¼ã¿
            try:
                full_path = self.project_path / file_path
                if full_path.exists():
                    with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°åˆ†æ
                    if 'try:' in content:
                        files_with_try_except += 1
                        structure_files['try_except'].append(file_path)
                        
                        if re.search(r'except\s+[A-Z][a-zA-Z]*Error', content):
                            files_with_specific_exceptions += 1
                            structure_files['specific_exceptions'].append(file_path)
                        
                        if re.search(r'except\s*:', content):
                            files_with_bare_except += 1
                            structure_files['bare_except'].append(file_path)
                    
                    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
                    if '"""' in content or "'''" in content:
                        files_with_docstrings += 1
                        structure_files['docstrings'].append(file_path)
                    
                    # å‹ãƒ’ãƒ³ãƒˆåˆ†æ
                    if re.search(r'->\s*[A-Za-z]', content) or re.search(r':\s*[A-Z][a-zA-Z]*', content):
                        files_with_type_hints += 1
                        structure_files['type_hints'].append(file_path)
                    
                    # ãƒ­ã‚°è¨˜éŒ²åˆ†æ
                    if re.search(r'(logging|log\.|logger)', content):
                        files_with_logging += 1
                        structure_files['logging'].append(file_path)
                    
                    # ã‚¯ãƒ©ã‚¹ç¶™æ‰¿åˆ†æ
                    if 'classes' in result and result['classes']:
                        files_with_classes += 1
                        if re.search(r'class\s+\w+\([^)]+\):', content):
                            files_with_inheritance += 1
                            structure_files['inheritance'].append(file_path)
                            
            except Exception:
                continue
        
        total_files = len(file_results)
        
        # å…·ä½“çš„ä¾‹å¤–å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³
        if files_with_specific_exceptions >= self.min_pattern_frequency:
            confidence = files_with_specific_exceptions / max(files_with_try_except, 1)
            
            if confidence >= self.min_confidence_score:
                patterns.append(EnhancedCodePattern(
                    pattern_id='specific_exception_handling',
                    pattern_type=PatternType.ERROR_HANDLING,
                    pattern_regex=r'except\s*:',
                    confidence_score=confidence,
                    frequency=files_with_specific_exceptions,
                    evidence_files=structure_files['specific_exceptions'][:3],
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯å…·ä½“çš„ãªä¾‹å¤–ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®šã—ãŸå‡¦ç†ãŒæ¨™æº–ã§ã™',
                    severity='HIGH',
                    auto_fixable=False
                ))
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
        if files_with_docstrings >= self.min_pattern_frequency:
            confidence = files_with_docstrings / total_files
            if confidence >= 0.5:  # 50%ä»¥ä¸Šã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦èªè­˜
                patterns.append(EnhancedCodePattern(
                    pattern_id='docstring_usage',
                    pattern_type=PatternType.DOCUMENTATION,
                    pattern_regex=r'def\s+\w+[^:]*:\s*$',
                    confidence_score=confidence,
                    frequency=files_with_docstrings,
                    evidence_files=structure_files['docstrings'][:3],
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯docstringã«ã‚ˆã‚‹æ–‡æ›¸åŒ–ãŒæ¨™æº–ã§ã™ï¼ˆé©ç”¨ç‡: {confidence:.1%}ï¼‰',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        # å‹ãƒ’ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
        if files_with_type_hints >= self.min_pattern_frequency:
            confidence = files_with_type_hints / total_files
            if confidence >= 0.4:  # 40%ä»¥ä¸Šã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦èªè­˜
                patterns.append(EnhancedCodePattern(
                    pattern_id='type_hints_usage',
                    pattern_type=PatternType.CODE_STRUCTURE,
                    pattern_regex=r'def\s+\w+\([^)]*\)\s*$',
                    confidence_score=confidence,
                    frequency=files_with_type_hints,
                    evidence_files=structure_files['type_hints'][:3],
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯å‹ãƒ’ãƒ³ãƒˆã®ä½¿ç”¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ï¼ˆé©ç”¨ç‡: {confidence:.1%}ï¼‰',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        # ãƒ­ã‚°è¨˜éŒ²ãƒ‘ã‚¿ãƒ¼ãƒ³
        if files_with_logging >= self.min_pattern_frequency:
            confidence = files_with_logging / total_files
            if confidence >= 0.3:  # 30%ä»¥ä¸Šã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦èªè­˜
                patterns.append(EnhancedCodePattern(
                    pattern_id='logging_usage',
                    pattern_type=PatternType.CODE_STRUCTURE,
                    pattern_regex=r'print\s*\(',
                    confidence_score=confidence,
                    frequency=files_with_logging,
                    evidence_files=structure_files['logging'][:3],
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯loggingãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä½¿ç”¨ãŒæ¨™æº–ã§ã™',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        # ã‚¯ãƒ©ã‚¹ç¶™æ‰¿ãƒ‘ã‚¿ãƒ¼ãƒ³
        if files_with_inheritance >= 2:  # æœ€ä½2ãƒ•ã‚¡ã‚¤ãƒ«
            confidence = files_with_inheritance / max(files_with_classes, 1)
            if confidence >= 0.4:  # 40%ä»¥ä¸Šã®ã‚¯ãƒ©ã‚¹ãŒç¶™æ‰¿ã‚’ä½¿ç”¨
                patterns.append(EnhancedCodePattern(
                    pattern_id='class_inheritance_pattern',
                    pattern_type=PatternType.CODE_STRUCTURE,
                    pattern_regex=r'class\s+\w+\s*:',
                    confidence_score=confidence,
                    frequency=files_with_inheritance,
                    evidence_files=structure_files['inheritance'][:3],
                    counter_examples=[],
                    suggested_message=f'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚¯ãƒ©ã‚¹ç¶™æ‰¿ã‚’æ´»ç”¨ã—ãŸè¨­è¨ˆãŒæ¨™æº–ã§ã™',
                    severity='INFO',
                    auto_fixable=False
                ))
        
        # bare exceptè­¦å‘Š
        if files_with_bare_except > 0:
            patterns.append(EnhancedCodePattern(
                pattern_id='bare_except_warning',
                pattern_type=PatternType.ERROR_HANDLING,
                pattern_regex=r'except\s*:',
                confidence_score=1.0,
                frequency=files_with_bare_except,
                evidence_files=structure_files['bare_except'][:3],
                counter_examples=[],
                suggested_message='bare exceptæ–‡ã¯é¿ã‘ã¦ã€å…·ä½“çš„ãªä¾‹å¤–ã‚¿ã‚¤ãƒ—ã‚’æŒ‡å®šã—ã¦ãã ã•ã„',
                severity='HIGH',
                auto_fixable=False
            ))
        
        return patterns
    
    def calculate_pattern_quality_score(self, pattern: EnhancedCodePattern) -> float:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # åŸºæœ¬ä¿¡é ¼åº¦
        base_score = pattern.confidence_score
        
        # é »åº¦ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        frequency_weight = min(1.0, pattern.frequency / 10.0)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        type_weights = {
            PatternType.SECURITY: 1.0,
            PatternType.ERROR_HANDLING: 0.9,
            PatternType.NAMING_CONVENTION: 0.8,
            PatternType.CODE_STRUCTURE: 0.7,
            PatternType.IMPORT_STYLE: 0.6,
            PatternType.PROJECT_SPECIFIC: 0.5
        }
        
        type_weight = type_weights.get(pattern.pattern_type, 0.5)
        
        # æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®—
        quality_score = base_score * 0.6 + frequency_weight * 0.2 + type_weight * 0.2
        
        return min(1.0, quality_score)
    
    def enhance_pattern_detection(self, file_results: List[Dict]) -> List[EnhancedCodePattern]:
        """å¼·åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºå®Ÿè¡Œ"""
        print("ğŸ” å¼·åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºé–‹å§‹...")
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        self.project_profile = self.analyze_project_structure(file_results)
        
        all_patterns = []
        
        # å„ç¨®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        all_patterns.extend(self.detect_naming_patterns(file_results))
        all_patterns.extend(self.detect_import_patterns(file_results))
        all_patterns.extend(self.detect_code_structure_patterns(file_results))
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        high_quality_patterns = []
        for pattern in all_patterns:
            quality_score = self.calculate_pattern_quality_score(pattern)
            
            if quality_score >= 0.75:  # é«˜å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿
                pattern.confidence_score = quality_score  # å“è³ªã‚¹ã‚³ã‚¢ã§æ›´æ–°
                high_quality_patterns.append(pattern)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³é–¢é€£æ€§åˆ†æ
        self.analyze_pattern_relationships(high_quality_patterns)
        
        self.detected_patterns = high_quality_patterns
        
        print(f"âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºå®Œäº†: {len(high_quality_patterns)}å€‹ã®é«˜å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º")
        
        return high_quality_patterns
    
    def analyze_pattern_relationships(self, patterns: List[EnhancedCodePattern]):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³é–“ã®é–¢é€£æ€§åˆ†æ"""
        for i, pattern1 in enumerate(patterns):
            for j, pattern2 in enumerate(patterns[i+1:], i+1):
                # åŒã˜ã‚¿ã‚¤ãƒ—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯é–¢é€£æ€§ãŒé«˜ã„
                if pattern1.pattern_type == pattern2.pattern_type:
                    pattern1.related_patterns.append(pattern2.pattern_id)
                    pattern2.related_patterns.append(pattern1.pattern_id)
    
    def generate_project_specific_rules(self) -> List[Dict[str, str]]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ãƒ«ãƒ¼ãƒ«ç”Ÿæˆ"""
        rules = []
        
        for pattern in self.detected_patterns:
            if pattern.confidence_score >= 0.8:  # é«˜ä¿¡é ¼åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿
                rule = {
                    'pattern_id': pattern.pattern_id,
                    'severity': pattern.severity,
                    'pattern': pattern.pattern_regex,
                    'message': pattern.suggested_message,
                    'category': pattern.pattern_type.value,
                    'confidence': pattern.confidence_score,
                    'auto_generated': True,
                    'evidence_count': pattern.frequency
                }
                rules.append(rule)
        
        return rules
    
    def get_detection_statistics(self) -> Dict[str, Any]:
        """æ¤œå‡ºçµ±è¨ˆæƒ…å ±å–å¾—"""
        if not self.detected_patterns:
            return {}
        
        by_type = defaultdict(int)
        by_severity = defaultdict(int)
        total_confidence = 0
        
        for pattern in self.detected_patterns:
            by_type[pattern.pattern_type.value] += 1
            by_severity[pattern.severity] += 1
            total_confidence += pattern.confidence_score
        
        return {
            'total_patterns': len(self.detected_patterns),
            'average_confidence': total_confidence / len(self.detected_patterns),
            'patterns_by_type': dict(by_type),
            'patterns_by_severity': dict(by_severity),
            'project_profile': asdict(self.project_profile) if self.project_profile else None
        }

def main():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    project_path = "/mnt/c/Users/tky99/dev/qualitygate"
    
    print("ğŸš€ Enhanced Pattern Detector ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    # ç°¡æ˜“ãƒ•ã‚¡ã‚¤ãƒ«çµæœä½œæˆï¼ˆå®Ÿéš›ã®ASTåˆ†æå™¨ã¨é€£æºäºˆå®šï¼‰
    test_file_results = [
        {
            'file_path': 'scripts/test_file.py',
            'functions': ['calculate_total', 'process_data', 'get_user_info'],
            'classes': ['DataProcessor', 'UserManager'],
            'imports': ['json', 'pathlib.Path', 'typing.Dict'],
            'complexity_score': 8
        },
        {
            'file_path': 'scripts/another_file.py',
            'functions': ['validate_input', 'save_results'],
            'classes': ['ResultHandler'],
            'imports': ['json', 'datetime', 'typing.List'],
            'complexity_score': 5
        }
    ]
    
    detector = EnhancedPatternDetector(project_path)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºå®Ÿè¡Œ
    patterns = detector.enhance_pattern_detection(test_file_results)
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ¯ æ¤œå‡ºçµæœ:")
    for pattern in patterns:
        print(f"  â€¢ {pattern.pattern_id}: {pattern.suggested_message}")
        print(f"    ä¿¡é ¼åº¦: {pattern.confidence_score:.2f}, é »åº¦: {pattern.frequency}")
    
    # çµ±è¨ˆæƒ…å ±
    stats = detector.get_detection_statistics()
    print(f"\nğŸ“Š çµ±è¨ˆæƒ…å ±:")
    print(f"  ç·ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {stats.get('total_patterns', 0)}")
    print(f"  å¹³å‡ä¿¡é ¼åº¦: {stats.get('average_confidence', 0):.2f}")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ãƒ«ãƒ¼ãƒ«ç”Ÿæˆ
    rules = detector.generate_project_specific_rules()
    print(f"\nğŸ“‹ ç”Ÿæˆãƒ«ãƒ¼ãƒ«æ•°: {len(rules)}")

if __name__ == "__main__":
    main()